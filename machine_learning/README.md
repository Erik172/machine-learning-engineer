# ğŸ¯ Machine Learning

Esta carpeta contiene implementaciones y apuntes de algoritmos fundamentales de Machine Learning tradicional.

## ğŸ“ Estructura de Contenidos

### ğŸ” Aprendizaje Supervisado

#### RegresiÃ³n
- **[ğŸ“ˆ Linear Regression](linear_regression/)** - RegresiÃ³n lineal simple
  - Conceptos bÃ¡sicos de regresiÃ³n
  - ImplementaciÃ³n desde cero y con scikit-learn
  - AnÃ¡lisis de residuos y mÃ©tricas de evaluaciÃ³n

- **[ğŸ“Š Multiple Linear Regression](multiple_linear_regression/)** - RegresiÃ³n lineal mÃºltiple
  - RegresiÃ³n con mÃºltiples variables
  - SelecciÃ³n de caracterÃ­sticas
  - Multicolinealidad y regularizaciÃ³n

- **[ğŸ”„ Polynomial Regression](polynomial_regression/)** - RegresiÃ³n polinomial
  - Relaciones no lineales
  - Overfitting y underfitting
  - ValidaciÃ³n cruzada

#### ClasificaciÃ³n
- **[ğŸ² Logistic Regression](logistic_regression/)** - RegresiÃ³n logÃ­stica
  - ClasificaciÃ³n binaria y multiclase
  - FunciÃ³n sigmoide y odds ratio
  - RegularizaciÃ³n L1 y L2

- **[ğŸ” K-Nearest Neighbors](knn/)** - K-Vecinos mÃ¡s cercanos
  - Algoritmo basado en instancias
  - SelecciÃ³n del valor k Ã³ptimo
  - MÃ©tricas de distancia

- **[ğŸ§  Perceptron](perceptron/)** - PerceptrÃ³n
  - Fundamentos de redes neuronales
  - Algoritmo de aprendizaje
  - Limitaciones y extensiones

### ğŸ” Aprendizaje No Supervisado

- **[ğŸ¯ Clustering](clustering/)** - Algoritmos de agrupamiento
  - K-Means clustering
  - EvaluaciÃ³n de clusters
  - SelecciÃ³n del nÃºmero Ã³ptimo de clusters

- **[ğŸ“‰ PCA](pca/)** - AnÃ¡lisis de Componentes Principales
  - ReducciÃ³n de dimensionalidad
  - Varianza explicada
  - VisualizaciÃ³n de datos de alta dimensiÃ³n

- **[ğŸ”— Hierarchical Clustering](hierarchical_clustering/)** - Clustering jerÃ¡rquico
  - Dendrogramas
  - Linkage methods
  - ComparaciÃ³n con K-Means

### ğŸ® Aprendizaje por Refuerzo

- **[ğŸ® Reinforcement Learning](reinforcement_learning/)** - Fundamentos de RL
  - Q-Learning bÃ¡sico
  - PolÃ­tica vs valor
  - ExploraciÃ³n vs explotaciÃ³n

## ğŸ› ï¸ Herramientas Utilizadas

- **Python 3.8+**
- **NumPy** - ComputaciÃ³n numÃ©rica
- **Pandas** - ManipulaciÃ³n de datos
- **Scikit-learn** - Algoritmos de ML
- **Matplotlib/Seaborn** - VisualizaciÃ³n
- **Jupyter Notebooks** - Desarrollo interactivo

## ğŸ“š Conceptos Clave Cubiertos

### Fundamentos
- Diferencia entre aprendizaje supervisado y no supervisado
- Overfitting vs Underfitting
- Bias-Variance tradeoff
- ValidaciÃ³n cruzada

### Preprocesamiento
- Limpieza de datos
- NormalizaciÃ³n y estandarizaciÃ³n
- CodificaciÃ³n de variables categÃ³ricas
- Manejo de valores faltantes

### EvaluaciÃ³n de Modelos
- MÃ©tricas para regresiÃ³n (MSE, MAE, RÂ²)
- MÃ©tricas para clasificaciÃ³n (Accuracy, Precision, Recall, F1)
- Curvas ROC y AUC
- Matrices de confusiÃ³n

### OptimizaciÃ³n
- Gradient Descent
- RegularizaciÃ³n (L1, L2)
- SelecciÃ³n de hiperparÃ¡metros
- Grid Search y Random Search

## ğŸ¯ Objetivos de Aprendizaje

Al completar esta secciÃ³n, deberÃ­as ser capaz de:

- [ ] Implementar algoritmos bÃ¡sicos de ML desde cero
- [ ] Usar scikit-learn para problemas reales
- [ ] Evaluar y comparar diferentes modelos
- [ ] Aplicar tÃ©cnicas de preprocesamiento adecuadas
- [ ] Interpretar resultados y mÃ©tricas
- [ ] Identificar y solucionar problemas comunes

## ğŸ“– Recursos Recomendados

### Libros
- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
- "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman
- "Pattern Recognition and Machine Learning" - Christopher Bishop

### Cursos
- Andrew Ng's Machine Learning Course (Coursera)
- CS229 Machine Learning (Stanford)

### DocumentaciÃ³n
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

## ğŸš€ PrÃ³ximos Pasos

1. Completa los notebooks en orden secuencial
2. Practica con datasets reales de Kaggle
3. Implementa algoritmos desde cero para entender mejor
4. Avanza a Deep Learning una vez dominados estos conceptos

---

ğŸ’¡ **Tip**: La prÃ¡ctica constante es clave. Intenta aplicar cada algoritmo a diferentes tipos de problemas para entender sus fortalezas y limitaciones. 